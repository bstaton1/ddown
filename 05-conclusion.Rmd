# Conclusions {#ch5}

\noindent
In writing this dissertation that summarizes my research over the last 3.5 years, I sought to develop, evaluate, and illustrate the application of quantitative tools that may be used to address challenges in salmon management, with particular focus on stocks in western Alaska. Specifically, the tools sought to reduce uncertainty in decision-making (in the case of the run timing forecast in Chapter \@ref(ch2)) and inform policy analyses by identifying and measuring the shape and magnitude of trade-offs among competing objectives (for in-season management in Chapter \@ref(ch3) and long-term management in Chapter \@ref(ch4)). In a broad sense, I believe I have accomplished this objective. The work presented in this dissertation provides a detailed look at ways quantitative tools can be used in the management of salmon fisheries in western Alaska -- some were novel to salmon management, all were novel with respect to the Kuskokwim River. This final chapter serves as my reflection on my doctoral work, including further insights on each of the three primary research projects I completed as well as my time working in Kuskokwim River management system at the Yukon Delta National Wildlife Refuge during the summers of 2016 -- 2018.

## Further insights on each project

### Chapter 2: Run timing forecasts

\noindent
My work on developing run timing forecasts for Kuskokwim River Chinook salmon has not proven as fruitful as I would have hoped when we wrote the grant proposal. In each year since its inception following the 2016 season, the forecast model did not provide good forecasts of $D_{50}$: both 2017 and 2018 were moderately late runs yet the forecast model suggested the runs would be several days early. Furthermore, a subsequent analysis [@staton-catalano-2019] strongly suggested that using the forecast model provides no utility for improving perceptions of run size based on test fishery data. The cause for this finding is two-fold. First, although the environmental relationships were present for all evaluated variables (Figure \@ref(fig:relationships); Table \@ref(tab:coefs-table)), the residual variability was too high to result in accurate and precise forecasts based on them. Second, inter-annual variability in the Bethel Test Fishery catchability [_i_._e_., the fraction of total run captured; the inverse is commonly referred to as "run-per-index"; @flynn-hilborn-2004] is the dominant cause of uncertainty in using this index for predicting run size for much of the season, not run timing. @staton-catalano-2019 illustrated that the average CV of abundance predictions from a relationship between historical abundance and cumulative catch per effort each day was approximately 38% early in the season and 30% at the end of the season (Figure 4 therein). So even after the test fishery is done catching Chinook salmon, a large amount of uncertainty still remains in the actual run size (this finding was the same for methods that included and excluded the run timing forecast). Based on the variability of errors made by these predictions, it seems this level of uncertainty is appropriate [also shown in Figure 4 of @staton-catalano-2019]. These findings illustrate that the Bethel Test Fishery is a poor index of run size, and that availability of the run timing forecast did not improve this situation. 

Still, the forecasting framework I developed was a statistically rigorous approach to dealing with high-dimensional variable selection over time and space. To my knowledge, the sliding climate window algorithm I employed has not widely been used in ecological problems. This must either be due to the computational costs or because it is not well-known, given it is an intuitive and objective approach to select temporal periods for prediction. After giving a talk on the forecasting approach I developed, a prominent ecologist in my field asked whether I thought this constituted a "data dredge" analysis, with the implication that it was a bad thing if so. In my view, data dredging is the practice of searching for all possible relationships that significantly support some hypothesis and discarding those that do not, or otherwise developing and confirming ad-hoc hypotheses based on such a search. First, the notion of statistical significance was never used in my analysis: all decisions were made based on actual out-of-sample predictive performance (through forecast cross-validation) or an index of predictive performance (Akaike’s Information Criterion). Second, no biological hypotheses were tested in this analysis. Instead, the search was conducted to find the variables most appropriate for forecasting run timing. In these cases, I think it is completely rational to perform as exhaustive of a search as possible, and the approach I developed served as an intuitive and objective means to do this.

It has been brought to my attention that methods exist that may provide better forecasts than the approach I used, which was simple/multiple regression at its core. Specifically, machine learning tools like random forests could show promise for this problem and others like it. Additionally, upon further reflection it is possible that having a continuous forecast of $D_{50}$ could be less useful than a discrete forecast of an early, average, or late run. Such a forecast could be obtained using a multinomial logistic regression [@agresti-2002, Ch. 7], which would provide predicted probabilities that the run will be early, average, or late. In my experience, uncertainty is more appropriately interpreted by managers when presented as the probability of outcomes rather than using uncertainty intervals. There would surely be some loss of resolution (_e_._g_., not all early runs are equally so), but the categories could be selected based on how the $D_{50}$ within each would influence the management inference. For example, there should exist some thresholds of early/late timing that would drastically change the inference from if it was an average run; I would propose that these thresholds be used to delineate the categories.

### Chapter 3: In-season MSE analyses

\noindent
In this stochastic MSE analysis of a large salmon-producing river system in western Alaska, I found several important implications, some that were known _a priori_ and some that were not. For example, the finding that more conservative substrategies should be favored in small runs as opposed to large runs makes intuitive sense. However, the finding that management performance was generally most sensitive to run timing in large runs rather than small runs was not necessarily known _a priori_, nor was the finding that good performance can be attained with a wide range of management strategies. This analysis was useful in that it provided an objective basis for strategy comparisons and necessitated critical thinking about the important drivers of system dynamics (_e_._g_., effort responses to fishery conditions) as well as the direct ways in which information influences a particular decision. It is my hope that when presented to fisheries managers and stakeholders in the region, perhaps a more-informed dialog may be had regarding the merits and detriments of candidate management strategies.

The most complex assessed management strategy (Strategy #4; explicit harvest target, selected probabilistically, updated with in-season information) is a computer-based representation of the strategy implemented by the U.S. Fish and Wildlife and the Kuskokwim River Inter-Tribal Fisheries Commission for the portion of the fishery within the Yukon Delta National Wildlife Refuge in the years 2015 -- 2018. Each year has differed in the method, rigor, and transparency of (1) initially selecting the season-wide harvest target ($H_T$), (2) utilizing in-season information to update $H_T$ and the weekly target ($H_{T,w}$), and (3) determining how much fishing opportunity should be allowed conditional on $H_{T,w}$. The overarching structure (_e_._g_., the use of $H_T$ based on an escapement limit threshold; $S_L$), however, is the same as the simulated strategy and the probabilistic selection of $H_T$ based on risk tolerance ($P^*$) and $S_L$ was conducted for the first time in 2018. 

With the current amount of information available for in-season management, this is among the most complex management strategies that could be used for the Kuskokwim Chinook salmon harvest control situation, and a key finding of the MSE analysis was that it did not perform overwhelmingly better than far simpler strategies. In the very smallest runs (50,000 -- 80,000), it did provide substantially better escapement performance than other policies, but only because the fishery was all but shut down completely. If this is desirable, the schedules used by Strategies #2 and #3 (Figure \@ref(fig:ms2-schedules)) could be altered to be more conservative for forecasts falling in this bin. Additionally, uncertainty in the forecast could be included by weighting schedules by the probability that the run will be in each run size bin according to the pre-season forecast. In the next smallest category (80,000 -- 130,000), the gains in escapement utility by using Strategy #4 were negligible in comparison to other simpler strategies, and came at the cost of reducing the harvest utility by approximately half (Figure \@ref(fig:btwn-ms-utilities)). Likewise, it showed no real gains in harvest equity or even substock exploitation utilities, though no assessed strategies strongly influenced these metrics. As a result of these findings, simple schedule-based strategies based solely on a pre-season forecast (as in Strategy #2) or combined with in-river species composition (as in Strategy #3) would perform well in the Kuskokwim and similar systems. Given the finding that many strategies perform similarly, however, perhaps the more important question now becomes which strategy could meet other objectives not included in this analysis (_e_._g_., fishers' desire to know when to expect fishing opportunities far in advance, desire to fish early in the season, _etc_.) and is transparent to the parties involved.

### Chapter 4: Multi-stock spawner-recruit analyses

\noindent
For my last project, I evaluated spawner-recruit methods for mixed-stock salmon fisheries. I developed a novel state-space framework for simultaneously estimating spawner-recruit parameters from the substocks within a larger drainage basin when they are all harvested as a mixed-stock -- the method was shown to perform substantially better than simpler regression-based approaches that, though they have long been known for their problems [@ludwig-walters-1981; @walters-1985; @walters-martell-2004], they are still applied to estimate salmon population dynamics parameters and to provide management recommendations [@clark-etal-2009; @korman-english-2013]. 

An alternative assessment approach would be to attempt to fit separate state-space models to the individual substocks as opposed to the more integrated approach I developed. This approach should retain the benefits of (1) not needing to exclude some observations because they do not constitute fully observed brood year pairs and (2) separately modeling the population dynamics and observation processes to (at least partially) handle the time-series and errors-in-variables biases. However, given that not all substocks have age composition data, the individual models would require some additional assumptions in this regard, and the degree of recruitment synchrony among substocks would only be available as part of an ad-hoc analysis of patterns from individual substocks. The more integrated state-space approach I took was a rational use of the available age composition data: only substocks with observed data were fitted for age composition, and they informed the maturity model parameters to be used for other substocks. Additionally, by incorporating a covariance matrix for recruitment variability, the degree of synchrony in substock dynamics could be informed by years with data on multiple substocks, which could be then used to inform the latent recruitment states in cases where there were fewer observations to inform them. Further, as computationally intensive as the model I developed was, this independent state-space model approach would be even more so given independent MCMC sampling would need to be conducted for each substock, which is a primary reason why it was not evaluated here. 

Although the state-space model was applied only to the Kuskokwim River data and the simulation was designed to mimic the data collection and substock heterogeneity for that system, the model potentially has wide applicability to other systems. Many salmon populations are harvested in mixed stocks; good examples include: the Columbia River in the northwestern contiguous United States, the Fraser and Skeena River drainages in British Columbia, Canada, the Bristol Bay stocks in southwestern Alaska, and the Yukon River in western Alaska and Canada. All of these systems are composed of several distinct spawning units, some portion of the harvest occurs as a mixed-stock, and should have data time series at least as rich as the Kuskokwim River Chinook salmon data set I used. Granted, in some situations modifications would be necessary for each specific case. For example, in the Bristol Bay fishery for sockeye salmon, some harvest occurs by “intercept fleets”, where fishers in one district may also harvest fish from other stocks that are migrating through that area but some harvest also occurs in-river. This kind of situation would require more detailed harvest information separated by mixed- and non-mixed sources, but I believe this would be within the abilities of the state-space model given the data are available.

## Reflections on working for USFWS

\noindent
In 2016 -- 2018, I took on a more-involved role in the management of Kuskokwim River salmon fisheries by working as a Pathways Student^[Unofficial title: Quantitative Ecologist] with the U.S. Fish at Wildlife Service at the Yukon Delta National Wildlife Refuge based out of Bethel, AK. Between May and August of these years, I abandoned my graduate work^[And my loving and understanding girlfriend (as of 2016), fiancée (as of 2017), and wife (as of 2018)] and focused on in-season salmon assessment. In this role, I lead several efforts dealing with providing information to managers: (1) compiling, analyzing, and presenting run assessment information in consistent formats^[Referred to as the "Daily Assessment Updates", over 250 documents were produced using `{rmarkdown}`; examples available upon request.], (2) developing and applying statistically rigorous approaches to estimating harvest and effort arising from short-duration block-openers^[Documented in @staton-coggins-2016, @staton-coggins-2017, @staton-2018, plus a synthesis manuscript currently in preparation] and presenting this information to managers, and (3) presenting assessments of the risk of seeing undesirable escapement outcomes conditional on different harvest levels^[2018 only; with the aid of a Shiny application I wrote, which has become commonly known as the "$P^*$ model" (\url{https://bstaton.shinyapps.io/BayesTool/}).]. I have enjoyed this role enormously, and it was highly rewarding to apply my quantitative skills to applied management problems, and to see the inferences be used in decision-making. Though there was a distinct boundary between the topics I worked on in-season in this role and my more academic work (_i_._e_., presented in Chapters \@ref(ch2), \@ref(ch3), \@ref(ch4) herein), I certainly used what I learned in each aspect to inform the other. I have no doubt my summers spent in Bethel resulted in better dissertation research, particularly with respect to developing the operating model and candidate management strategies used in Chapter \@ref(ch4), and that I would have been less valuable to the management system without the quantitative training I have received in my graduate program.
